{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romenlaw/generative/blob/main/diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ai.gopubby.com/you-dont-need-backpropagation-to-train-neural-networks-anymore-e989d75564cb\n",
        "\n",
        "# NoProp\n",
        "The NoProp algorithm borrows insights from [Diffusion models](https://arxiv.org/abs/1503.03585) (primarily used for image generation tasks) and applies them to an Image classification (supervised learning [link text](https://en.wikipedia.org/wiki/Supervised_learning)) task.\n",
        "\n",
        "## 1. Stochastic Forward / Denoising Process\n",
        "This process is represented by p as shown below:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*3flQoGDA25QeDGwRHEOFSw.png)\n",
        "\n",
        "It models how we can start with noise and, through a series of steps, denoise it toward the final representation z(T)​, which is then used to predict the label y.\n",
        "\n",
        "Mathematically, it is the joint probability of all intermediate noisy representations z(0), …, z(T) and the label y, given x.\n",
        "\n",
        "In the equation:\n",
        "\n",
        "* p(z(0)​) describes the standard Gaussian noise\n",
        "* p(z(t) ∣ z(t−1), x) describes how each layer denoises the input noise\n",
        "*p(y ∣ z(T)​) describes how y is classified based on the final representation z(T)\n",
        "* p(z(t) ∣ z(t−1), x) is parameterized using a neural network as follows:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*ChP3TlaZPSWv1KZup_Y7-g.png)\n",
        "\n",
        "where:\n",
        "\n",
        "* neural network û with parameters θ, weighted by a(t), predicts the denoised representation based on the noisy inputs z(t-1) and x\n",
        "* b(t) ​⋅ z(t−1)​ represents a weighted skip connection\n",
        "* √c(t) ​​⋅ ϵ(t)​ represents random Gaussian noise\n",
        "* a(t), b(t), c(t) are scalers that are used to weigh the three different parts of the equation\n",
        "\n",
        "## 2. Backward Nosing Process / Variational Posterior\n",
        "This process is represented by q as shown below:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*Lid_FWZZypM2E2PpoKmsLA.png)\n",
        "\n",
        "It models how we can start with a label y (in the form of its embedding u(y)) and add noise step by step until we get the noise z(0).\n",
        "\n",
        "Mathematically, it is the probability of the final noisy representation z(T) given the label y and input x.\n",
        "\n",
        "In the equation:\n",
        "\n",
        "* q(z(T) ​∣ y) describes the representation z(T) given label y\n",
        "* xq(z(t−1) ​∣ z(t)​) describes the reverse diffusion process of reaching earlier noisy representations by adding more noise\n",
        "\n",
        "q(z(T) ​∣ y) is given using the following equation:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*4zOeuxuZVaOV_H5v7FWigg.png)\n",
        "\n",
        "This means that it is a Gaussian distribution over the latent variable z(T) where √αˉ(T)​​⋅ u(y)​ is the mean and 1 — αˉ(T) is the variance.\n",
        "\n",
        "u(y) is the label embedding and αˉ(T)​ tells how much of u(y) remains after applying the noising process.\n",
        "\n",
        "q(z(t−1) ​∣ z(t)​) is given by the following equation:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*MYg13gyFLi-sAwT9lGOhgg.png)\n",
        "\n",
        "This means that it is a Gaussian distribution over the latent variable z(t-1) where √α(t-1)​​⋅ z(t)​ is the mean and 1 — α(t-1) is the variance.\n",
        "\n",
        "α(t−1)​ is a noise scheduling parameter that controls how much of the original signal is preserved at timestep t-1.\n",
        "\n",
        "Note that the terms α and αˉ come from a [fixed cosine](https://arxiv.org/abs/2102.09672) [noise schedule](https://arxiv.org/abs/2301.10972).\n",
        "\n",
        "## Defining the Loss\n",
        "\n",
        "The training objective of the NoProp algorithm is to maximise the log-likelihood of the correct label log⁡ p(y∣x).\n",
        "\n",
        "But directly optimising this log-likelihood is computationally infeasible because it requires integrating over all possible high-dimensional latent variables z(0)​, … , z(T).\n",
        "\n",
        "As a workaround, we instead maximise a variational lower bound on it called the [Evidence Lower Bound (ELBO)](https://en.wikipedia.org/wiki/Evidence_lower_bound).\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*KZTSrhjpsEutwUe10yH7zg.png)\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*TKg00IjZp3-O6ECBh78zbw.png)\n",
        "\n",
        "The NoProp loss is derived from this expression as:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*nJn4RJBQn5tmQp2Grshq2A.png)\n",
        "\n",
        "(The mathematical details of this derivation are described in [Section A.4 of the original research paper.)](https://arxiv.org/pdf/2503.24322)\n",
        "\n",
        "This looks very complex, but is easy to understand.\n",
        "\n",
        "On the right-hand side of the equation:\n",
        "\n",
        "* The first term is the **[Cross-entropy loss](https://en.wikipedia.org/wiki/Cross-entropy)**, which measures how accurately the final representation z(T) can be used to predict the correct label y.\n",
        "* The second term is the **[Kullback-Leibler (KL) divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)** between the distribution of the starting representation z(0) and the standard Gaussian noise distribution. This [regularization](https://www.ibm.com/think/topics/regularization) encourages both of these distributions to be similar, which is necessary for the diffusion process to work properly.\n",
        "* The third term is the **layer-wise Denoising loss**, which measures how well each layer denoises by comparing how close its output is to the true label embedding (given by the L2 loss term).\n",
        "In the equation, η is a hyperparameter and the term SNR is the Signal-to-Noise Ratio, given by the following equation:\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*Ye8uBABNhBpI88UzbYVpyw.png)\n",
        "\n",
        "As t increases (as we move towards the later layers), the signal increases (noise decreases) and hence SNR increases. This makes the overall denoising loss larger.\n",
        "\n",
        "This means that the model is penalized more for errors from the later layers (t closer to T) than the earlier ones.\n",
        "\n",
        "## Training Process\n",
        "During training, the network learns to denoise noisy label embeddings at each layer, without doing a full forward or backward pass through the network.\n",
        "\n",
        "For a given input-label pair (x, y) an embedding matrix W(embed) maps the labels y to embeddings u(y) with each row of this matrix corresponding to the embedding u(y)​ of the label y.\n",
        "\n",
        "Noise is first added to u(y) to create z(t).\n",
        "\n",
        "Then, each neural network layer û(θ)(z(t−1) , x) is trained independently to denoise the previous noisy representation z(t-1)​ by predicting the clean embedding u(y) using input x.\n",
        "\n",
        "The training loss is calculated, and the network parameters are updated while minimising this loss, using an optimiser.\n",
        "\n",
        "The training algorithm is summarised using the pseudocode shown below.\n",
        "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*HZ_9Pj7Za98PH954LvLaIQ.png)\n",
        "\n",
        "## Inference Process\n",
        "During inference, the network with T total layers/ blocks is given Gaussian noise z(0).\n",
        "\n",
        "Each layer, starting from Gaussian noise z(0), sequentially takes the output z(t-1) from the previous layer, and input x, to produce the next denoised representation z(t).\n",
        "\n",
        "This results in a sequence of intermediate forms of the noise at each layer, represented by z(0)​, z(1)​, …, z(t), z(T-1), z(T)​.\n",
        "\n",
        "At the final step t = T, the output z(T)​ is passed through a classifier to predict the final label ŷ.\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fcmo4yHdD48D-RDIeTSvWw.png)\n",
        "z(0) is successively transformed towards z(T) with each layer represented by u(t) conditioned on input x, ultimately resulting in the the predicted label ŷ.\n",
        "\n",
        "\n",
        "## Layer/Block Architecture\n",
        "\n",
        "Each layer/ block û(θ)(z(t−1) , x), as described above, is a complex neural network in itself that takes:\n",
        "\n",
        "* the input x and processes it through a [convolutional](https://en.wikipedia.org/wiki/Convolutional_neural_network) embedding module, followed by a fully connected layer\n",
        "* noised representation from the previous layer z(t-1), and processes it using a fully connected network with skip connections\n",
        "\n",
        "These inputs are then passed through additional fully connected layers to produce logits.\n",
        "\n",
        "The logits go through a [softmax function](https://en.wikipedia.org/wiki/Softmax_function), producing a probability distribution over class embeddings.\n",
        "\n",
        "The final output is obtained by computing a weighted sum of the class embeddings using this probability distribution.\n",
        "\n",
        "![architecture](https://miro.medium.com/v2/resize:fit:720/format:webp/1*RVYlwvq1Q8obFInm5c1ekA.png)\n",
        "\n",
        "## How Well Does NoProp Perform?\n",
        "What we described above was the **Discrete-Time (DT)** variant of NoProp called **NoProp-DT**.\n",
        "\n",
        "This is called so because it is implemented to model the diffusion process in discrete time steps, rather than continuously.\n",
        "\n",
        "There are two other variants of it, namely:\n",
        "\n",
        "* **NoProp-CT (Continuous-Time)**: This variant uses a continuous noise schedule and models the diffusion process over a continuous time span instead of discrete steps.\n",
        "* **NoProp-FM (Flow Matching)**: This variant learns the vector field that transports noise towards the predicted label embedding via an [ordinary differential equation (ODE)](https://arxiv.org/abs/2210.02747), rather than the denoising approach.\n",
        "\n",
        "All of these variants are compared with backpropagation and previous backpropagation-free methods for image classification tasks on three benchmark datasets:\n",
        "\n",
        "* MNIST: A dataset of 70,000 grayscale images of handwritten digits (each 28 x 28 pixels), across 10 classes (digits 0–9)\n",
        "* CIFAR-10: A dataset of 60,000 color images (each 32 x 32 pixels) across 10 different object classes\n",
        "* CIFAR-100: A dataset of 60,000 color images (each 32 x 32 pixels) across 100 different object classes\n",
        "\n",
        "Experiments show that NoProp achieves **performance comparable to or better than backpropagation and other backpropagation-free methods** on all three datasets.\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fUAsOxuOiAOiYHhdWPRd7A.png)\n",
        "\n",
        "Alongside this, NoProp consumes less GPU memory during training as compared to other methods.\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*54MkisKtuOXg3BXkmd1Ztw.png)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bUEtb8wIox1z"
      },
      "id": "bUEtb8wIox1z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding No-Prop From Scratch"
      ],
      "metadata": {
        "id": "l3lnKKu8vB--"
      },
      "id": "l3lnKKu8vB--"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9c9135ee",
      "metadata": {
        "id": "9c9135ee",
        "outputId": "ab285430-dc77-4a70-b89c-cf8c917e73c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device is  cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "  device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print (\"device is \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Denoising Block\n",
        "This is the denoising neural network block (û(θ)) that takes:\n",
        "\n",
        "* an image x\n",
        "* a noisy intermediate representation z(t-1), and\n",
        "* the class embedding matrix W_embed that contains label embeddings u(y) as\n",
        "its rows\n",
        "\n",
        "It then learns to denoise the noisy latent vector z(t-1) and bringing it closer to the true label embedding u(y) using information from the image x.\n",
        "\n",
        "It returns the next representation z(t) given these inputs.\n",
        "\n",
        "Unlike conventional neural networks, each of these blocks independently learn to remove noise towards the label embedding."
      ],
      "metadata": {
        "id": "0zonY8nco73u"
      },
      "id": "0zonY8nco73u"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0649ab52",
      "metadata": {
        "id": "0649ab52"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Denoising block\n",
        "\n",
        "class DenoiseBlock(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_classes):\n",
        "        super().__init__()\n",
        "        # Image path\n",
        "        self.conv_path = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256)\n",
        "        )\n",
        "\n",
        "        # Noisy embedding path\n",
        "        self.fc_z1 = nn.Linear(embedding_dim, 256)\n",
        "        self.bn_z1 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.fc_z2 = nn.Linear(256, 256)\n",
        "        self.bn_z2 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.fc_z3 = nn.Linear(256, 256)\n",
        "        self.bn_z3 = nn.BatchNorm1d(256)\n",
        "\n",
        "        # Combined downstream path\n",
        "        self.fc_f1 = nn.Linear(256 + 256, 256)\n",
        "        self.bn_f1 = nn.BatchNorm1d(256)\n",
        "        self.fc_f2 = nn.Linear(256, 128)\n",
        "        self.bn_f2 = nn.BatchNorm1d(128)\n",
        "        self.fc_out = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x, z_prev, W_embed):\n",
        "        # Image features\n",
        "        x_feat = self.conv_path(x)\n",
        "\n",
        "        # Features from noisy embedding\n",
        "        h1 = F.relu(self.bn_z1(self.fc_z1(z_prev)))\n",
        "        h2 = F.relu(self.bn_z2(self.fc_z2(h1)))\n",
        "        h3 = self.bn_z3(self.fc_z3(h2))\n",
        "\n",
        "        z_feat = h3 + h1 # Residual connection\n",
        "\n",
        "        # Combine and predict logits\n",
        "        h_f = torch.cat([x_feat, z_feat], dim=1)\n",
        "        h_f = F.relu(self.bn_f1(self.fc_f1(h_f)))\n",
        "        h_f = F.relu(self.bn_f2(self.fc_f2(h_f)))\n",
        "        logits = self.fc_out(h_f)\n",
        "\n",
        "        # Softmax on logits\n",
        "        p = F.softmax(logits, dim=1)\n",
        "        z_next = p @ W_embed\n",
        "\n",
        "        return z_next, logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the NonProp-DT Model\n",
        "\n",
        "This model combines the label denoising through a T-step diffusion process, using independently trained DenoiseBlocks."
      ],
      "metadata": {
        "id": "erxInwtkpf_B"
      },
      "id": "erxInwtkpf_B"
    },
    {
      "cell_type": "code",
      "source": [
        "# NoProp-DT model\n",
        "\n",
        "class NoPropDT(nn.Module):\n",
        "    def __init__(self, num_classes, embedding_dim, T, eta):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.T = T\n",
        "        self.eta = eta\n",
        "\n",
        "        # Stacking up the Denoise blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            DenoiseBlock(embedding_dim, num_classes) for _ in range(T)\n",
        "        ])\n",
        "\n",
        "        # Class-embedding matrix (W_embed)\n",
        "        self.W_embed = nn.Parameter(torch.randn(num_classes, embedding_dim) * 0.1)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
        "\n",
        "        # Cosine noise schedule\n",
        "        t = torch.arange(1, T+1, dtype=torch.float32)\n",
        "        alpha_t = torch.cos(t / T * (math.pi/2))**2\n",
        "        alpha_bar = torch.cumprod(alpha_t, dim=0)\n",
        "        snr = alpha_bar / (1 - alpha_bar)\n",
        "        snr_prev = torch.cat([torch.tensor([0.], dtype=snr.dtype), snr[:-1]], dim=0)\n",
        "        snr_diff = snr - snr_prev\n",
        "\n",
        "        self.register_buffer('alpha_bar', alpha_bar)\n",
        "        self.register_buffer('snr_diff', snr_diff)\n",
        "\n",
        "    def forward_denoise(self, x, z_prev, t):\n",
        "        return self.blocks[t](x, z_prev, self.W_embed)[0]\n",
        "\n",
        "    def classify(self, z):\n",
        "        return self.classifier(z)\n",
        "\n",
        "    def inference(self, x):\n",
        "        B = x.size(0)\n",
        "        z = torch.randn(B, self.embedding_dim, device=x.device)\n",
        "\n",
        "        for t in range(self.T):\n",
        "            z = self.forward_denoise(x, z, t)\n",
        "\n",
        "        return self.classify(z)"
      ],
      "metadata": {
        "id": "ilegJi78plpn"
      },
      "id": "ilegJi78plpn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Training Function\n",
        "This function trains the NoProp-DT model (creating by combining T Denoising blocks without using backpropagation."
      ],
      "metadata": {
        "id": "J0tL7QujvQRZ"
      },
      "id": "J0tL7QujvQRZ"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function for training NoProp-DT\n",
        "\n",
        "def train_nopropdt(model, train_loader, test_loader, epochs, lr, weight_decay):\n",
        "    # Using AdamW optimizer\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # Dict to store metrics\n",
        "    history = {'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "\n",
        "        for t in range(model.T):\n",
        "            for x, y in train_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                uy = model.W_embed[y]\n",
        "                alpha_bar_t = model.alpha_bar[t]\n",
        "                noise = torch.randn_like(uy)\n",
        "                z_t = torch.sqrt(alpha_bar_t) * uy + torch.sqrt(1 - alpha_bar_t) * noise\n",
        "\n",
        "                z_pred, _ = model.blocks[t](x, z_t, model.W_embed)\n",
        "                loss_l2 = F.mse_loss(z_pred, uy)\n",
        "                loss = 0.5 * model.eta * model.snr_diff[t] * loss_l2\n",
        "\n",
        "                if t == model.T - 1:\n",
        "                    logits = model.classifier(z_pred)\n",
        "                    loss_ce = F.cross_entropy(logits, y)\n",
        "                    loss_kl = 0.5 * uy.pow(2).sum(dim=1).mean()\n",
        "                    loss = loss + loss_ce + loss_kl\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "        # Training accuracy\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in train_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                preds = model.inference(x).argmax(dim=1)\n",
        "                correct += (preds == y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation accuracy\n",
        "        val_correct, val_total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                preds = model.inference(x).argmax(dim=1)\n",
        "                val_correct += (preds == y).sum().item()\n",
        "                val_total += y.size(0)\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        # Storing accuracy history\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs}  \"\n",
        "              f\"TrainAcc={100 * train_acc:.2f}%  ValAcc={100 * val_acc:.2f}%\")\n",
        "\n",
        "    # Plotting Training and Validation accuracy\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epochs + 1), history['train_acc'], label='Train Accuracy')\n",
        "    plt.plot(range(1, epochs + 1), history['val_acc'], label='Validation Accuracy')\n",
        "    plt.title(\"Accuracy Curve\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\n Final Test Accuracy: {100 * val_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "VeLWBbLyvUuQ"
      },
      "id": "VeLWBbLyvUuQ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Hyperparameters\n",
        "The hyperparameters used by the authors in their experiments are shown below.\n",
        "![](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*kOK_VvPVi2huiBrlF9lxMg.png)\n",
        "\n",
        "There’s just a minor change: we're training the model for only 10 epochs instead of 100, as this amount of training is sufficient to achieve satisfactory results for our tutorial."
      ],
      "metadata": {
        "id": "KHrPT94tvenI"
      },
      "id": "KHrPT94tvenI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "T = 10\n",
        "eta = 0.1\n",
        "embedding_dim = 512\n",
        "batch_size = 128\n",
        "lr = 1e-3\n",
        "epochs = 10\n",
        "weight_decay = 1e-3"
      ],
      "metadata": {
        "id": "R5nYxVTjvpWq"
      },
      "id": "R5nYxVTjvpWq",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading MNIST Dataset\n",
        "We will not apply data augmentation techniques on the MNIST dataset. This is similar to the experiments from the original research paper."
      ],
      "metadata": {
        "id": "37wKgIFlvrr_"
      },
      "id": "37wKgIFlvrr_"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "\n",
        "# Loading MNIST\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_set  = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(test_set,  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Jziany1Kvw0D"
      },
      "id": "Jziany1Kvw0D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialising the Model\n",
        "\n",
        "Let’s set up the model with the hyperparameters that we defined."
      ],
      "metadata": {
        "id": "uHwEKnRxv5vT"
      },
      "id": "uHwEKnRxv5vT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing model\n",
        "\n",
        "model = NoPropDT(num_classes=10, embedding_dim=embedding_dim, T=T, eta=eta).to(device)"
      ],
      "metadata": {
        "id": "mEdJolkPwAZa"
      },
      "id": "mEdJolkPwAZa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "eRYVGa0jwDNK"
      },
      "id": "eRYVGa0jwDNK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Begin training\n",
        "\n",
        "train_nopropdt(model, train_loader, test_loader, epochs=epochs, lr=lr, weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "RoL4_xofwFPk"
      },
      "id": "RoL4_xofwFPk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualising Predictions"
      ],
      "metadata": {
        "id": "9lNzdv6hwH5I"
      },
      "id": "9lNzdv6hwH5I"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot predictions\n",
        "\n",
        "def show_predictions(model, test_loader, class_names=None, num_images = 16):\n",
        "    model.eval()\n",
        "    images_shown = 0\n",
        "    plt.figure(figsize=(5, 5))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model.inference(x)\n",
        "            preds = logits.argmax(dim=1)\n",
        "\n",
        "            for i in range(x.size(0)):\n",
        "                if images_shown >= num_images:\n",
        "                    break\n",
        "\n",
        "                plt.subplot(int(num_images**0.5), int(num_images**0.5), images_shown + 1)\n",
        "                img = x[i].cpu().squeeze(0)\n",
        "                plt.imshow(img, cmap='gray')\n",
        "                actual = class_names[y[i]] if class_names else y[i].item()\n",
        "                pred = class_names[preds[i]] if class_names else preds[i].item()\n",
        "                plt.title(f\"Pred: {pred}\\nTrue: {actual}\", fontsize=8)\n",
        "                plt.axis('off')\n",
        "\n",
        "                images_shown += 1\n",
        "\n",
        "            if images_shown >= num_images:\n",
        "                break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XUlNWgntwP-g"
      },
      "id": "XUlNWgntwP-g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class names for MNIST dataset\n",
        "class_names = [str(i) for i in range(10)]\n",
        "\n",
        "# Visualising predictions\n",
        "show_predictions(model, test_loader)"
      ],
      "metadata": {
        "id": "qgVm2fFVwRJ4"
      },
      "id": "qgVm2fFVwRJ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Further Reading\n",
        "* [Research paper titled ‘NoProp: Training Neural Networks without Back-propagation or Forward-propagation’ published in ArXiv](https://arxiv.org/abs/2503.24322)\n",
        "* [Notebook containing the code for training a neural network with NoProp-DT on the MNIST dataset](https://github.com/ashishbamania/Tutorials-On-Artificial-Intelligence/blob/main/Training%20Without%20Backpropagation/NoPropDT_on_MNIST.ipynb)\n",
        "* [Research paper titled ‘Denoising Diffusion Probabilistic Models’ published in ArXiv](https://arxiv.org/abs/2006.11239)\n",
        "* [Research paper titled ‘Deep Unsupervised Learning using Nonequilibrium Thermodynamics’ published in ArXiv](https://arxiv.org/abs/1503.03585)\n",
        "* [Research paper titled ‘Learning representations by back-propagating errors’ published in Nature](https://www.nature.com/articles/323533a0)"
      ],
      "metadata": {
        "id": "VgNuggrxwWg0"
      },
      "id": "VgNuggrxwWg0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}